{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os.path as op\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary from behavioural csv(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"/Users/nalsharif/science/PING/train_img_beh.csv\"\n",
    "\n",
    "delimiter = ','\n",
    "with open(csv_file, 'r') as data_file:\n",
    "    data = csv.reader(data_file, delimiter=delimiter)\n",
    "    headers = next(data)[1:] # header names starting from 2nd column in csv\n",
    "    behav = dict()\n",
    "    for row in data:\n",
    "        behav[  row[0]  ] = dict()\n",
    "        for idx, item in enumerate(row[1:]):\n",
    "            try:\n",
    "                behav[row[0]][  headers[idx]  ] = float(item)\n",
    "            except ValueError as e:\n",
    "                behav[row[0]][  headers[idx]  ] = float('nan')\n",
    "                \n",
    "# behav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUTURE REF: for test set\n",
    "\n",
    "do the above + following again for the test set, just change csv but keep other variables, change pkl names\n",
    "\n",
    "```\n",
    "csv_file = \"/Users/nalsharif/science/PING/test_img_beh.csv\"\n",
    "\n",
    "delimiter = ','\n",
    "with open(csv_file, 'r') as data_file:\n",
    "    data = csv.reader(data_file, delimiter=delimiter)\n",
    "    headers = next(data)[1:] # header names starting from 2nd column in csv\n",
    "    test_behav = dict()\n",
    "    for row in data:\n",
    "        test_behav[  row[0]  ] = dict()\n",
    "        for idx, item in enumerate(row[1:]):\n",
    "            try:\n",
    "                test_behav[row[0]][  headers[idx]  ] = float(item)\n",
    "            except ValueError as e:\n",
    "                test_behav[row[0]][  headers[idx]  ] = float('nan')\n",
    "```\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get pickles from output dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/nalsharif/science/PING/PING_bids/desikan/desikan_locality_statistic.pkl',\n",
       " '/Users/nalsharif/science/PING/PING_bids/desikan/desikan_number_non_zeros.pkl',\n",
       " '/Users/nalsharif/science/PING/PING_bids/desikan/desikan_study_mean_connectome.pkl',\n",
       " '/Users/nalsharif/science/PING/PING_bids/desikan/desikan_degree_distribution.pkl',\n",
       " '/Users/nalsharif/science/PING/PING_bids/desikan/desikan_betweenness_centrality.pkl',\n",
       " '/Users/nalsharif/science/PING/PING_bids/desikan/desikan_edge_weight.pkl',\n",
       " '/Users/nalsharif/science/PING/PING_bids/desikan/desikan_eigen_sequence.pkl',\n",
       " '/Users/nalsharif/science/PING/PING_bids/desikan/desikan_clustering_coefficients.pkl']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadir = '/Users/nalsharif/science/PING/PING_bids/desikan/'\n",
    "pickles = [op.join(datadir, fl) for fl in os.listdir(datadir) if fl.endswith('.pkl')]\n",
    "pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_stat = pkl.load(open(pickles[0], 'rb'))\n",
    "locstat = local_stat['locality_statistic']\n",
    "\n",
    "numb_nonzero = pkl.load(open(pickles[1], 'rb'))\n",
    "nnonzero = numb_nonzero['number_non_zeros']\n",
    "\n",
    "study_mean_conn = pkl.load(open(pickles[2], 'rb'))\n",
    "meanconn = study_mean_conn['study_mean_connectome']\n",
    "\n",
    "degree_dist = pkl.load(open(pickles[3], 'rb'))\n",
    "degdist = degree_dist['degree_distribution']\n",
    "\n",
    "btwn_central = pkl.load(open(pickles[4], 'rb'))\n",
    "bwcent = btwn_central['betweenness_centrality']\n",
    "\n",
    "edge_weight = pkl.load(open(pickles[5], 'rb'))\n",
    "edgewt = edge_weight['edge_weight']\n",
    "\n",
    "eigen_seq = pkl.load(open(pickles[6], 'rb'))\n",
    "eigseq = eigen_seq['eigen_sequence']\n",
    "\n",
    "coef_clust = pkl.load(open(pickles[7], 'rb'))\n",
    "cfclust = coef_clust['clustering_coefficients']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these are organised with subjs as keys: locstat, nnonzero, bwcent, edgewt, eigseq, cfclust\n",
    "\n",
    "these are organised with other feat as keys: degdist\n",
    "\n",
    "these are organised as an array: meanconn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace subjids in dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "locstat_new = {}\n",
    "for sub in locstat.keys():\n",
    "    locstat_new[sub.split(\"-\")[1].split(\"_\")[0]] = locstat[sub]\n",
    "    \n",
    "nnonzero_new = {}\n",
    "for sub in nnonzero.keys():\n",
    "    nnonzero_new[sub.split(\"-\")[1].split(\"_\")[0]] = nnonzero[sub]\n",
    "    \n",
    "bwcent_new = {}\n",
    "for sub in bwcent.keys():\n",
    "    bwcent_new[sub.split(\"-\")[1].split(\"_\")[0]] = bwcent[sub]\n",
    "    \n",
    "edgewt_new = {}\n",
    "for sub in edgewt.keys():\n",
    "    edgewt_new[sub.split(\"-\")[1].split(\"_\")[0]] = edgewt[sub]\n",
    "    \n",
    "eigseq_new = {}\n",
    "for sub in eigseq.keys():\n",
    "    eigseq_new[sub.split(\"-\")[1].split(\"_\")[0]] = eigseq[sub]\n",
    "    \n",
    "cfclust_new = {}\n",
    "for sub in cfclust.keys():\n",
    "    cfclust_new[sub.split(\"-\")[1].split(\"_\")[0]] = cfclust[sub]\n",
    "    \n",
    "degdist_new = {}\n",
    "for degtype in degdist.keys():\n",
    "    degdist_new[degtype] = {}\n",
    "    for sub in degdist[degtype].keys():\n",
    "        degdist_new[degtype][sub.split(\"-\")[1].split(\"_\")[0]] = degdist[degtype][sub]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe use this code to create dataframes of everything at the same time?\n",
    "- degseq_df = pd.DataFrame.from_dict(sub,orient = 'index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull list of subjids from both ndmg data + behav dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_subjids = []\n",
    "for item in locstat.keys():\n",
    "    pkl_subjids.append(item.split(\"-\")[1].split(\"_\")[0])\n",
    "    subjids = [subj for subj in pkl_subjids if subj in behav]\n",
    "    \n",
    "subjids = list(set(subjids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(597, list)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subjids), type(subjids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dictionary of just ages (for future reference/binning purposes, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.42"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age = {}\n",
    "for subj in subjids:\n",
    "    try:\n",
    "        age[subj] = behav[subj]['Age']\n",
    "    except KeyError as e:\n",
    "        age[subj] = 0\n",
    "\n",
    "age['P0007']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save pickles for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat connectome feature info\n",
    "pkl.dump(locstat_new, open('/Users/nalsharif/code/nooralsh/ping_proc/data/train_locstat.pkl','wb'))\n",
    "pkl.dump(nnonzero_new, open('/Users/nalsharif/code/nooralsh/ping_proc/data/train_nnonzero.pkl','wb'))\n",
    "pkl.dump(bwcent_new, open('/Users/nalsharif/code/nooralsh/ping_proc/data/train_bwcent.pkl','wb'))\n",
    "pkl.dump(edgewt_new, open('/Users/nalsharif/code/nooralsh/ping_proc/data/train_edgewt_new.pkl','wb'))\n",
    "pkl.dump(eigseq_new, open('/Users/nalsharif/code/nooralsh/ping_proc/data/train_eigseq.pkl','wb'))\n",
    "pkl.dump(cfclust_new, open('/Users/nalsharif/code/nooralsh/ping_proc/data/train_cfclust.pkl','wb'))\n",
    "pkl.dump(degdist_new, open('/Users/nalsharif/code/nooralsh/ping_proc/data/train_degdist.pkl','wb'))\n",
    "pkl.dump(meanconn, open('/Users/nalsharif/code/nooralsh/ping_proc/data/train_meanconn.pkl','wb'))\n",
    "\n",
    "# dat TRAIN demographic info\n",
    "pkl.dump(age, open('/Users/nalsharif/code/nooralsh/ping_proc/data/train_ages.pkl', 'wb')) # dict of subjids: ages\n",
    "pkl.dump(behav, open('/Users/nalsharif/code/nooralsh/ping_proc/data/train_behav.pkl', 'wb')) # dict of subjids: {demog/cog: data}\n",
    "pkl.dump(subjids, open('/Users/nalsharif/code/nooralsh/ping_proc/data/train_subjids.pkl','wb')) # list of subjids\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
